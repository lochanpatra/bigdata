{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1tJb9zieiSiBq0mov4UHtg3vP57xJqfiz",
      "authorship_tag": "ABX9TyO39YhgsmotOoHQNp8Ly5mQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lochanpatra/bigdata/blob/main/Bigdata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQVYR-d_kb2b"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"NYC Taxi Data Analysis\") \\\n",
        "    .config(\"spark.driver.memory\", \"8g\") \\\n",
        "    .config(\"spark.executor.memory\", \"16g\") \\\n",
        "    .getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark.sql import SparkSession\n",
        "\n",
        "# spark = SparkSession.builder \\\n",
        "#     .appName(\"ParquetAnalysis\") \\\n",
        "#     .getOrCreate()\n"
      ],
      "metadata": {
        "id": "dL6hlSLExilK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Parquet file\n",
        "df_parquet = spark.read.parquet(\"/content/drive/MyDrive/DATA FOR USES/yellow_tripdata_2024-01.parquet\")\n",
        "\n",
        "df_parquet.show(5)\n",
        "df_parquet.printSchema()\n"
      ],
      "metadata": {
        "id": "6gj_o9vwp_kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of rows\n",
        "print(f\"Total rows: {df_parquet.count()}\")\n",
        "\n",
        "# Summary statistics\n",
        "df_parquet.describe().show()\n",
        "\n",
        "# Unique values in key categorical fields\n",
        "df_parquet.select(\"payment_type\", \"VendorID\").distinct().show()\n"
      ],
      "metadata": {
        "id": "uc_IYM9sq2Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df_parquet.dropna(subset=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\"])\n"
      ],
      "metadata": {
        "id": "t_jpghD9q2kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df_clean.filter(\n",
        "    (df_clean.passenger_count > 0) &\n",
        "    (df_clean.trip_distance > 0) &\n",
        "    (df_clean.trip_distance < 100)  # cap outliers\n",
        ")\n"
      ],
      "metadata": {
        "id": "4p50ow6MrHT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Trip Duration in minutes:"
      ],
      "metadata": {
        "id": "TG-DD-UqrU1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import unix_timestamp, col\n",
        "\n",
        "df_transformed = df_filtered.withColumn(\n",
        "    \"trip_duration_minutes\",\n",
        "    (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")) / 60\n",
        ")\n"
      ],
      "metadata": {
        "id": "pQvEDA6arPh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract day of week and hour of day:"
      ],
      "metadata": {
        "id": "TsyypaVZrcsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import hour, dayofweek\n",
        "\n",
        "df_transformed = df_transformed.withColumn(\"pickup_hour\", hour(\"tpep_pickup_datetime\"))\n",
        "df_transformed = df_transformed.withColumn(\"pickup_day_of_week\", dayofweek(\"tpep_pickup_datetime\"))\n"
      ],
      "metadata": {
        "id": "tRprZMxqrPn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Average trip distance and fare per day:"
      ],
      "metadata": {
        "id": "iGxbJjqArlSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_date, avg\n",
        "\n",
        "df_transformed.groupBy(to_date(\"tpep_pickup_datetime\").alias(\"trip_date\")) \\\n",
        "    .agg(\n",
        "        avg(\"trip_distance\").alias(\"avg_distance\"),\n",
        "        avg(\"fare_amount\").alias(\"avg_fare\")\n",
        "    ) \\\n",
        "    .orderBy(\"trip_date\") \\\n",
        "    .show()\n"
      ],
      "metadata": {
        "id": "ZgjBQ1WsrPvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Popular pickup hours:"
      ],
      "metadata": {
        "id": "OK31a4u6rzoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_transformed.groupBy(\"pickup_hour\").count().orderBy(\"pickup_hour\").show()\n"
      ],
      "metadata": {
        "id": "hWODM5EDrvBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Select only a sample or aggregated data to convert\n",
        "df_sample = df_transformed.select(\"pickup_hour\").groupBy(\"pickup_hour\").count().orderBy(\"pickup_hour\")\n",
        "\n",
        "# Convert to Pandas\n",
        "pdf_sample = df_sample.toPandas()\n"
      ],
      "metadata": {
        "id": "WttK2UMBrvJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Bar plot of trips per pickup hour\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=pdf_sample, x=\"pickup_hour\", y=\"count\", palette=\"viridis\")\n",
        "\n",
        "plt.title(\"Number of Trips per Hour of Day\")\n",
        "plt.xlabel(\"Pickup Hour\")\n",
        "plt.ylabel(\"Number of Trips\")\n",
        "plt.xticks(range(0, 24))\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L6cGUkYCrvdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select needed columns and filter extreme outliers\n",
        "df_plot = df_transformed.select(\"trip_distance\", \"fare_amount\") \\\n",
        "    .filter((col(\"trip_distance\") < 50) & (col(\"fare_amount\") < 200)) \\\n",
        "    .sample(fraction=0.01, seed=42)  # 1% random sample\n",
        "\n",
        "# Convert to Pandas\n",
        "pdf_plot = df_plot.toPandas()\n"
      ],
      "metadata": {
        "id": "XQSQG-tyrrnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=pdf_plot, x=\"trip_distance\", y=\"fare_amount\", alpha=0.3)\n",
        "\n",
        "plt.title(\"Trip Distance vs Fare Amount\")\n",
        "plt.xlabel(\"Trip Distance (miles)\")\n",
        "plt.ylabel(\"Fare Amount (USD)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3ywLUAtWrrxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MjUfohLDrP4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TnbDhmtmrHbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_timestamp, to_date, hour\n",
        "\n",
        "df = df.withColumn(\"pickup_datetime\", to_timestamp(\"tpep_pickup_datetime\")) \\\n",
        "       .withColumn(\"pickup_date\", to_date(\"tpep_pickup_datetime\")) \\\n",
        "       .withColumn(\"pickup_hour\", hour(\"tpep_pickup_datetime\"))\n"
      ],
      "metadata": {
        "id": "ilwt9Nrix1wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_trips = df.groupBy(\"pickup_hour\").count().orderBy(\"pickup_hour\")\n"
      ],
      "metadata": {
        "id": "NDOs5fxpx4uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_fare = df.groupBy(\"pickup_date\").sum(\"fare_amount\").orderBy(\"pickup_date\")\n"
      ],
      "metadata": {
        "id": "srE7ryuMx41l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "payment_type_counts = df.groupBy(\"payment_type\").count().orderBy(\"count\", ascending=False)\n"
      ],
      "metadata": {
        "id": "F4b1FngPx485"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_hourly = hourly_trips.toPandas()\n",
        "pdf_daily = daily_fare.toPandas()\n",
        "pdf_payment = payment_type_counts.toPandas()\n"
      ],
      "metadata": {
        "id": "-H7TJlqryCsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_hourly = hourly_trips.limit(24).toPandas()\n"
      ],
      "metadata": {
        "id": "pDR7zKRqye0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sufZ86k6yCz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lPc2CFw2yC6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_timestamp, to_date, hour\n",
        "\n",
        "df = df_parquet.withColumn(\"pickup_datetime\", to_timestamp(\"tpep_pickup_datetime\")) \\\n",
        "               .withColumn(\"dropoff_datetime\", to_timestamp(\"tpep_dropoff_datetime\")) \\\n",
        "               .withColumn(\"pickup_date\", to_date(\"tpep_pickup_datetime\")) \\\n",
        "               .withColumn(\"pickup_hour\", hour(\"tpep_pickup_datetime\"))\n"
      ],
      "metadata": {
        "id": "iMiCTazGv4g_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Number of trips per hour"
      ],
      "metadata": {
        "id": "VQLKRqTMwFYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_counts = df.groupBy(\"pickup_hour\").count().orderBy(\"pickup_hour\")\n",
        "# hourly_counts.show()\n"
      ],
      "metadata": {
        "id": "NL4ZDU2Mv42_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_fare = df.groupBy(\"pickup_date\").sum(\"fare_amount\").orderBy(\"pickup_date\")\n",
        "# daily_fare.show()\n"
      ],
      "metadata": {
        "id": "9vMep096v4-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "payment_counts = df.groupBy(\"payment_type\").count().orderBy(\"count\", ascending=False)\n",
        "# payment_counts.show()\n"
      ],
      "metadata": {
        "id": "i_xh3LdowbRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_hourly = hourly_counts.toPandas()\n",
        "pdf_daily_fare = daily_fare.toPandas()\n",
        "pdf_payment = payment_counts.toPandas()\n"
      ],
      "metadata": {
        "id": "K4IsAABtwbZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qBRzqR0Qwbge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok pyspark\n"
      ],
      "metadata": {
        "id": "_vza3fVtmEkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app.py\n",
        "# import streamlit as st\n",
        "# from pyspark.sql import SparkSession\n",
        "# import pandas as pd\n",
        "# import altair as alt\n",
        "\n",
        "# # Initialize Spark\n",
        "# spark = SparkSession.builder.appName(\"Parquet Viewer\").getOrCreate()\n",
        "\n",
        "# st.title(\"ðŸš• NYC Yellow Taxi Data Dashboard\")\n",
        "\n",
        "# # Path to Parquet file\n",
        "# file_path = \"/content/drive/MyDrive/DATA FOR USES/yellow_tripdata_2024-01.parquet\"\n",
        "\n",
        "# # Load data\n",
        "# df_spark = spark.read.parquet(file_path)\n",
        "\n",
        "# # Convert small sample to pandas\n",
        "# df = df_spark.limit(5000).toPandas()\n",
        "\n",
        "# # Show data schema\n",
        "# st.subheader(\"ðŸ“„ Data Schema\")\n",
        "# st.text(df_spark._jdf.schema().treeString())\n",
        "\n",
        "# # Display raw data\n",
        "# st.subheader(\"ðŸ§¾ Sample Data\")\n",
        "# st.dataframe(df)\n",
        "\n",
        "# # Add sidebar filters\n",
        "# st.sidebar.header(\"ðŸ” Filter Options\")\n",
        "# if \"passenger_count\" in df.columns:\n",
        "#     passenger_counts = sorted(df[\"passenger_count\"].dropna().unique())\n",
        "#     selected_passenger = st.sidebar.selectbox(\"Passenger Count\", passenger_counts)\n",
        "#     df = df[df[\"passenger_count\"] == selected_passenger]\n",
        "\n",
        "# # Convert datetime if needed\n",
        "# if \"tpep_pickup_datetime\" in df.columns:\n",
        "#     df[\"pickup_hour\"] = pd.to_datetime(df[\"tpep_pickup_datetime\"]).dt.hour\n",
        "\n",
        "# # Visualizations\n",
        "# st.subheader(\"ðŸ“Š Visualizations\")\n",
        "\n",
        "# # Trip count by hour\n",
        "# if \"pickup_hour\" in df.columns:\n",
        "#     chart = alt.Chart(df).mark_bar().encode(\n",
        "#         x=alt.X('pickup_hour:O', title=\"Hour of Day\"),\n",
        "#         y=alt.Y('count()', title=\"Number of Trips\"),\n",
        "#         tooltip=[\"count()\"]\n",
        "#     ).properties(\n",
        "#         title=\"Trips by Pickup Hour\",\n",
        "#         width=600,\n",
        "#         height=400\n",
        "#     )\n",
        "#     st.altair_chart(chart)\n",
        "\n",
        "# # Histogram of trip distance\n",
        "# if \"trip_distance\" in df.columns:\n",
        "#     st.subheader(\"ðŸ“ Trip Distance Distribution\")\n",
        "#     st.bar_chart(df[\"trip_distance\"].clip(upper=20).value_counts().sort_index())\n",
        "\n",
        "# # Optional: average fare by passenger count\n",
        "# if \"passenger_count\" in df.columns and \"total_amount\" in df.columns:\n",
        "#     st.subheader(\"ðŸ’µ Avg Fare by Passenger Count\")\n",
        "#     avg_fare = df.groupby(\"passenger_count\")[\"total_amount\"].mean()\n",
        "#     st.bar_chart(avg_fare)\n"
      ],
      "metadata": {
        "id": "wwDJQUQTmEsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app.py\n",
        "# import streamlit as st\n",
        "# from pyspark.sql import SparkSession\n",
        "# import pandas as pd\n",
        "# import altair as alt\n",
        "\n",
        "# # Initialize Spark\n",
        "# spark = SparkSession.builder.appName(\"Taxi Dashboard\").getOrCreate()\n",
        "\n",
        "# # Load Parquet\n",
        "# file_path = \"/content/drive/MyDrive/DATA FOR USES/yellow_tripdata_2024-01.parquet\"\n",
        "# df_spark = spark.read.parquet(file_path)\n",
        "\n",
        "# # Convert to Pandas (limit to manageable rows)\n",
        "# df = df_spark.limit(5000).toPandas()\n",
        "\n",
        "# # Sidebar filters\n",
        "# st.sidebar.header(\"ðŸ” Filters\")\n",
        "# if \"passenger_count\" in df.columns:\n",
        "#     passenger_counts = sorted(df[\"passenger_count\"].dropna().unique())\n",
        "#     selected_passenger = st.sidebar.selectbox(\"Passenger Count\", passenger_counts)\n",
        "#     df = df[df[\"passenger_count\"] == selected_passenger]\n",
        "\n",
        "# # Time-based features\n",
        "# if \"tpep_pickup_datetime\" in df.columns:\n",
        "#     df[\"pickup_hour\"] = pd.to_datetime(df[\"tpep_pickup_datetime\"]).dt.hour\n",
        "\n",
        "# # --- Visualizations ---\n",
        "\n",
        "# st.title(\"ðŸš– NYC Yellow Taxi Data\")\n",
        "\n",
        "# # 1. Bar chart: Trips by Pickup Hour\n",
        "# if \"pickup_hour\" in df.columns:\n",
        "#     st.subheader(\"â° Trips by Hour of Day\")\n",
        "#     chart = alt.Chart(df).mark_bar().encode(\n",
        "#         x=alt.X('pickup_hour:O', title=\"Hour\"),\n",
        "#         y=alt.Y('count()', title=\"Number of Trips\"),\n",
        "#         tooltip=[\"count()\"]\n",
        "#     ).properties(width=600, height=400)\n",
        "#     st.altair_chart(chart)\n",
        "\n",
        "# # 2. Histogram: Trip Distance\n",
        "# if \"trip_distance\" in df.columns:\n",
        "#     st.subheader(\"ðŸ“ Trip Distance Distribution\")\n",
        "#     st.bar_chart(df[\"trip_distance\"].clip(upper=20).value_counts().sort_index())\n",
        "\n",
        "# # 3. Average fare by passenger count\n",
        "# if \"passenger_count\" in df.columns and \"total_amount\" in df.columns:\n",
        "#     st.subheader(\"ðŸ’µ Avg Fare by Passenger Count\")\n",
        "#     avg_fare = df.groupby(\"passenger_count\")[\"total_amount\"].mean()\n",
        "#     st.bar_chart(avg_fare)\n"
      ],
      "metadata": {
        "id": "J2zpU08aqDdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "\n",
        "# Initialize Spark\n",
        "spark = SparkSession.builder.appName(\"Taxi Dashboard\").getOrCreate()\n",
        "\n",
        "# Load Parquet\n",
        "file_path = \"/content/drive/MyDrive/DATA FOR USES/yellow_tripdata_2024-01.parquet\"\n",
        "df_spark = spark.read.parquet(file_path)\n",
        "\n",
        "# Convert to Pandas (limit for Colab performance)\n",
        "df = df_spark.limit(5000).toPandas()\n",
        "\n",
        "# Sidebar filter\n",
        "st.sidebar.header(\"ðŸ” Filters\")\n",
        "if \"passenger_count\" in df.columns:\n",
        "    counts = sorted(df[\"passenger_count\"].dropna().unique())\n",
        "    selected_count = st.sidebar.selectbox(\"Passenger Count\", counts)\n",
        "    df = df[df[\"passenger_count\"] == selected_count]\n",
        "\n",
        "# Preprocessing\n",
        "if \"tpep_pickup_datetime\" in df.columns and \"tpep_dropoff_datetime\" in df.columns:\n",
        "    df[\"pickup_datetime\"] = pd.to_datetime(df[\"tpep_pickup_datetime\"])\n",
        "    df[\"dropoff_datetime\"] = pd.to_datetime(df[\"tpep_dropoff_datetime\"])\n",
        "    df[\"trip_duration_min\"] = (df[\"dropoff_datetime\"] - df[\"pickup_datetime\"]).dt.total_seconds() / 60\n",
        "    df[\"pickup_hour\"] = df[\"pickup_datetime\"].dt.hour\n",
        "\n",
        "# === VISUALIZATIONS ===\n",
        "\n",
        "st.title(\"ðŸš– NYC Yellow Taxi Data Dashboard\")\n",
        "\n",
        "# 1. Pickup Map\n",
        "if \"pickup_longitude\" in df.columns and \"pickup_latitude\" in df.columns:\n",
        "    st.subheader(\"ðŸ“ Pickup Locations Map\")\n",
        "    pickup_map = df[[\"pickup_latitude\", \"pickup_longitude\"]].dropna()\n",
        "    pickup_map = pickup_map.rename(columns={\"pickup_latitude\": \"lat\", \"pickup_longitude\": \"lon\"})\n",
        "    st.map(pickup_map)\n",
        "\n",
        "# 2. Dropoff Map\n",
        "if \"dropoff_longitude\" in df.columns and \"dropoff_latitude\" in df.columns:\n",
        "    st.subheader(\"ðŸ Dropoff Locations Map\")\n",
        "    dropoff_map = df[[\"dropoff_latitude\", \"dropoff_longitude\"]].dropna()\n",
        "    dropoff_map = dropoff_map.rename(columns={\"dropoff_latitude\": \"lat\", \"dropoff_longitude\": \"lon\"})\n",
        "    st.map(dropoff_map)\n",
        "\n",
        "# 3. Trip Duration Histogram\n",
        "if \"trip_duration_min\" in df.columns:\n",
        "    st.subheader(\"â±ï¸ Trip Duration (minutes)\")\n",
        "    st.bar_chart(df[\"trip_duration_min\"].clip(upper=60).value_counts().sort_index())\n",
        "\n",
        "# 4. Trips by Hour\n",
        "if \"pickup_hour\" in df.columns:\n",
        "    st.subheader(\"ðŸ“ˆ Trips by Hour of Day\")\n",
        "    chart = alt.Chart(df).mark_bar().encode(\n",
        "        x=alt.X('pickup_hour:O', title=\"Hour\"),\n",
        "        y=alt.Y('count()', title=\"Trips\"),\n",
        "        tooltip=[\"count()\"]\n",
        "    ).properties(width=600, height=400)\n",
        "    st.altair_chart(chart)\n",
        "\n",
        "# 5. Average Fare by Passenger Count\n",
        "if \"passenger_count\" in df.columns and \"total_amount\" in df.columns:\n",
        "    st.subheader(\"ðŸ’µ Avg Fare by Passenger Count\")\n",
        "    avg_fare = df.groupby(\"passenger_count\")[\"total_amount\"].mean()\n",
        "    st.bar_chart(avg_fare)\n"
      ],
      "metadata": {
        "id": "6-MWYvSUqrh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2wf1M8DB9CWeZUIBKwhcSAmu4m3_4K4TEKVvFuv9wVYrpc2R4\n"
      ],
      "metadata": {
        "id": "uQhyj96XnfAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill any existing tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Start streamlit\n",
        "get_ipython().system_raw('streamlit run app.py &')\n",
        "\n",
        "# Create a public URL\n",
        "url = ngrok.connect(8501)\n",
        "print(\"Streamlit app is live at:\", url)\n"
      ],
      "metadata": {
        "id": "GZaKLH6ImMXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kr4YnOAPo3Hd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}